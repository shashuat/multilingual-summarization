_attn_implementation_autoset:
    value: true
_name_or_path:
    value: microsoft/Phi-4-mini-instruct
_wandb:
    value:
        cli_version: 0.19.7
        m:
            - "1": eval_runtime
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": train/global_step
              "6":
                - 3
              "7": []
            - "1": train/example_count
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": epoch
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": eval_loss
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": eval_samples_per_second
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": eval/samples_per_second
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": eval_steps_per_second
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": train/grad_norm
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": train/epoch
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": train/loss
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": eval/runtime
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": eval/steps_per_second
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": model_size_mb
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": train/learning_rate
              "5": 2
              "6":
                - 1
                - 3
              "7": []
            - "1": eval/loss
              "5": 2
              "6":
                - 1
                - 3
              "7": []
        python_version: 3.11.11
        t:
            "1":
                - 1
                - 11
                - 49
                - 51
                - 55
                - 71
                - 98
            "2":
                - 1
                - 11
                - 49
                - 51
                - 55
                - 71
                - 98
            "3":
                - 2
                - 7
                - 13
                - 16
                - 19
                - 23
                - 55
                - 61
                - 62
                - 66
            "4": 3.11.11
            "5": 0.19.7
            "6": 4.49.0
            "8":
                - 5
            "9":
                "1": transformers_trainer
            "12": 0.19.7
            "13": linux-x86_64
accelerator_config:
    value:
        dispatch_batches: null
        even_batches: true
        gradient_accumulation_kwargs: null
        non_blocking: false
        split_batches: false
        use_seedable_sampler: true
adafactor:
    value: false
adam_beta1:
    value: 0.9
adam_beta2:
    value: 0.999
adam_epsilon:
    value: 1e-08
add_cross_attention:
    value: false
all_params:
    value: 3841788928
architectures:
    value:
        - Phi3ForCausalLM
attention_bias:
    value: false
attention_dropout:
    value: 0
auto_find_batch_size:
    value: false
auto_map:
    value:
        AutoConfig: microsoft/Phi-4-mini-instruct--configuration_phi3.Phi3Config
        AutoModelForCausalLM: microsoft/Phi-4-mini-instruct--modeling_phi3.Phi3ForCausalLM
        AutoTokenizer: microsoft/Phi-4-mini-instruct--Xenova/gpt-4o
average_tokens_across_devices:
    value: false
bad_words_ids:
    value: null
batch_eval_metrics:
    value: false
begin_suppress_tokens:
    value: null
bf16:
    value: true
bf16_full_eval:
    value: false
bnb_compute_dtype:
    value: bfloat16
bos_token_id:
    value: 199999
chunk_size_feed_forward:
    value: 0
cross_attention_hidden_size:
    value: null
data_seed:
    value: null
dataloader_drop_last:
    value: false
dataloader_num_workers:
    value: 4
dataloader_persistent_workers:
    value: false
dataloader_pin_memory:
    value: true
dataloader_prefetch_factor:
    value: null
ddp_backend:
    value: null
ddp_broadcast_buffers:
    value: null
ddp_bucket_cap_mb:
    value: null
ddp_find_unused_parameters:
    value: false
ddp_timeout:
    value: 1800
debug:
    value: []
decoder_start_token_id:
    value: null
deepspeed:
    value: null
disable_tqdm:
    value: false
dispatch_batches:
    value: null
diversity_penalty:
    value: 0
do_eval:
    value: true
do_predict:
    value: false
do_sample:
    value: false
do_train:
    value: false
early_stopping:
    value: false
effective_batch_size:
    value: 8
embd_pdrop:
    value: 0
encoder_no_repeat_ngram_size:
    value: 0
eos_token_id:
    value: 199999
eval_accumulation_steps:
    value: null
eval_delay:
    value: 0
eval_do_concat_batches:
    value: true
eval_on_start:
    value: false
eval_steps:
    value: null
eval_strategy:
    value: epoch
eval_use_gather_object:
    value: false
evaluation_strategy:
    value: null
exponential_decay_length_penalty:
    value: null
finetuning_task:
    value: null
forced_bos_token_id:
    value: null
forced_eos_token_id:
    value: null
fp16:
    value: false
fp16_backend:
    value: auto
fp16_full_eval:
    value: false
fp16_opt_level:
    value: O1
fsdp:
    value: []
fsdp_config:
    value:
        min_num_params: 0
        xla: false
        xla_fsdp_grad_ckpt: false
        xla_fsdp_v2: false
fsdp_min_num_params:
    value: 0
fsdp_transformer_layer_cls_to_wrap:
    value: null
full_attn_mod:
    value: 1
full_determinism:
    value: false
gradient_accumulation_steps:
    value: 8
gradient_checkpointing:
    value: true
gradient_checkpointing_kwargs:
    value: null
greater_is_better:
    value: false
group_by_length:
    value: true
half_precision_backend:
    value: auto
hidden_act:
    value: silu
hidden_size:
    value: 3072
hub_always_push:
    value: false
hub_model_id:
    value: null
hub_private_repo:
    value: null
hub_strategy:
    value: every_save
hub_token:
    value: <HUB_TOKEN>
id2label:
    value:
        "0": LABEL_0
        "1": LABEL_1
ignore_data_skip:
    value: false
include_for_metrics:
    value: []
include_inputs_for_metrics:
    value: false
include_num_input_tokens_seen:
    value: false
include_tokens_per_second:
    value: false
initializer_range:
    value: 0.02
intermediate_size:
    value: 8192
interpolate_factor:
    value: 1
is_decoder:
    value: false
is_encoder_decoder:
    value: false
jit_mode_eval:
    value: false
label_names:
    value:
        - labels
label_smoothing_factor:
    value: 0
label2id:
    value:
        LABEL_0: 0
        LABEL_1: 1
language:
    value: fr
learning_rate:
    value: 0.0002
length_column_name:
    value: length
length_penalty:
    value: 1
lm_head_bias:
    value: false
load_best_model_at_end:
    value: true
local_rank:
    value: 0
log_level:
    value: passive
log_level_replica:
    value: warning
log_on_each_node:
    value: true
logging_dir:
    value: /Data/shash/mul/finetuned_models/logs
logging_first_step:
    value: false
logging_nan_inf_filter:
    value: true
logging_steps:
    value: 50
logging_strategy:
    value: steps
lora_alpha:
    value: 32
lora_dropout:
    value: 0.05
lora_r:
    value: 16
lr_scheduler_type:
    value: cosine
max_grad_norm:
    value: 1
max_length:
    value: 20
max_position_embeddings:
    value: 131072
max_steps:
    value: -1
max_target_length:
    value: 512
metric_for_best_model:
    value: loss
min_length:
    value: 0
mlp_bias:
    value: false
model/num_parameters:
    value: 3841788928
model_name:
    value: microsoft/Phi-4-mini-instruct
model_type:
    value: phi3
mp_parameters:
    value: ""
neftune_noise_alpha:
    value: null
no_cuda:
    value: false
no_repeat_ngram_size:
    value: 0
num_attention_heads:
    value: 24
num_beam_groups:
    value: 1
num_beams:
    value: 1
num_epochs:
    value: 3
num_hidden_layers:
    value: 32
num_key_value_heads:
    value: 8
num_return_sequences:
    value: 1
num_train_epochs:
    value: 3
optim:
    value: adamw_torch_fused
optim_args:
    value: null
optim_target_modules:
    value: null
original_max_position_embeddings:
    value: 4096
output_attentions:
    value: false
output_dir:
    value: /Data/shash/mul/finetuned_models
output_hidden_states:
    value: false
output_scores:
    value: false
overwrite_output_dir:
    value: false
pad_token_id:
    value: 199999
partial_rotary_factor:
    value: 0.75
past_index:
    value: -1
peft_config:
    value:
        default:
            auto_mapping: null
            base_model_name_or_path: microsoft/Phi-4-mini-instruct
            bias: none
            eva_config: null
            exclude_modules: null
            fan_in_fan_out: false
            inference_mode: false
            init_lora_weights: true
            layer_replication: null
            layers_pattern: null
            layers_to_transform: null
            lora_alpha: 32
            lora_bias: false
            lora_dropout: 0.05
            megatron_config: null
            megatron_core: megatron.core
            modules_to_save: null
            peft_type: LORA
            r: 16
            revision: null
            runtime_config:
                ephemeral_gpu_offload: false
            target_modules:
                - Wqkv
                - out_proj
                - up_proj
                - down_proj
            task_type: CAUSAL_LM
            use_dora: false
            use_rslora: false
per_device_eval_batch_size:
    value: 1
per_device_train_batch_size:
    value: 1
per_gpu_eval_batch_size:
    value: null
per_gpu_train_batch_size:
    value: null
prediction_loss_only:
    value: false
prefix:
    value: null
problem_type:
    value: null
push_to_hub:
    value: false
push_to_hub_model_id:
    value: null
push_to_hub_organization:
    value: null
push_to_hub_token:
    value: <PUSH_TO_HUB_TOKEN>
quantization:
    value: 4-bit
quantization_config:
    value:
        _load_in_4bit: true
        _load_in_8bit: false
        bnb_4bit_compute_dtype: bfloat16
        bnb_4bit_quant_storage: uint8
        bnb_4bit_quant_type: nf4
        bnb_4bit_use_double_quant: true
        llm_int8_enable_fp32_cpu_offload: false
        llm_int8_has_fp16_weight: false
        llm_int8_skip_modules: null
        llm_int8_threshold: 6
        load_in_4bit: true
        load_in_8bit: false
        quant_method: BITS_AND_BYTES
ray_scope:
    value: last
remove_invalid_values:
    value: false
remove_unused_columns:
    value: false
repetition_penalty:
    value: 1
report_to:
    value:
        - wandb
resid_pdrop:
    value: 0
restore_callback_states_from_checkpoint:
    value: false
resume_from_checkpoint:
    value: null
return_dict:
    value: true
return_dict_in_generate:
    value: false
rms_norm_eps:
    value: 1e-05
rope_scaling:
    value:
        long_factor:
            - 1
            - 1.118320672
            - 1.250641126
            - 1.398617824
            - 1.564103225
            - 1.74916897
            - 1.956131817
            - 2.187582649
            - 2.446418898
            - 2.735880826
            - 3.059592084
            - 3.421605075
            - 3.826451687
            - 4.279200023
            - 4.785517845
            - 5.351743533
            - 5.984965424
            - 6.693110555
            - 7.485043894
            - 8.370679318
            - 9.36110372
            - 10.4687158
            - 11.70738129
            - 13.09260651
            - 14.64173252
            - 16.37415215
            - 18.31155283
            - 20.47818807
            - 22.90118105
            - 25.61086418
            - 28.64115884
            - 32.03
            - 32.1
            - 32.13
            - 32.23
            - 32.6
            - 32.61
            - 32.64
            - 32.66
            - 32.7
            - 32.71
            - 32.93
            - 32.97
            - 33.28
            - 33.49
            - 33.5
            - 44.16
            - 47.77
        short_factor:
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
            - 1
        type: longrope
rope_theta:
    value: 10000
run_name:
    value: phi4-fr-r16-lr0.0002
sample_prompt:
    value: "<|system|>Vous êtes un expert en résumé. Votre tâche est de créer des résumés concis et complets \nqui capturent tous les points clés et les arguments principaux tout en évitant les détails inutiles. \nNe copiez pas simplement les premières phrases de l'article. Créez un résumé qui se tient \npar lui-même et couvre tout le contenu important de l'article.<|end|><|user|>Please summarize the following article: {{Infobox Maladie}}\nL{{'}}'''angiocholite''' est une '''infection de la bile sur obstacle li..."
save_on_each_node:
    value: false
save_only_model:
    value: false
save_safetensors:
    value: true
save_steps:
    value: 500
save_strategy:
    value: epoch
save_total_limit:
    value: 2
seed:
    value: 42
sep_token_id:
    value: null
skip_memory_metrics:
    value: true
sliding_window:
    value: 262144
split_batches:
    value: null
suppress_tokens:
    value: null
target_modules:
    value:
        - Wqkv
        - out_proj
        - up_proj
        - down_proj
task_specific_params:
    value: null
temperature:
    value: 1
tf_legacy_loss:
    value: false
tf32:
    value: null
tie_encoder_decoder:
    value: false
tie_word_embeddings:
    value: true
tokenizer_class:
    value: null
top_k:
    value: 50
top_p:
    value: 1
torch_compile:
    value: false
torch_compile_backend:
    value: null
torch_compile_mode:
    value: null
torch_dtype:
    value: bfloat16
torch_empty_cache_steps:
    value: null
torchdynamo:
    value: null
torchscript:
    value: false
tpu_metrics_debug:
    value: false
tpu_num_cores:
    value: null
train_batch_size:
    value: 1
train_examples:
    value: 3999
trainable_params:
    value: 5767168
trainable_percentage:
    value: 0.15011673228498618
transformers_version:
    value: 4.49.0
typical_p:
    value: 1
use_bfloat16:
    value: false
use_cache:
    value: false
use_cpu:
    value: false
use_ipex:
    value: false
use_legacy_prediction_loop:
    value: false
use_liger_kernel:
    value: false
use_mps_device:
    value: false
validation_examples:
    value: 501
vocab_size:
    value: 200064
warmup_ratio:
    value: 0.1
warmup_steps:
    value: 0
weight_decay:
    value: 0.01
